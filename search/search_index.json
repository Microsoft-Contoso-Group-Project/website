{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Contoso Chat Project","text":"<p>Welcome to the documentation site for the Contoso Chat project. This initiative is a collaborative effort by students at Imperial College London to reconstruct Microsoft's Contoso Chat retail copilot application open-source AI models from Hugging Face. Here, you'll find comprehensive information about our project, including technical details, progress updates, and insights from our journey.</p>"},{"location":"#team-members","title":"Team Members","text":"<ul> <li>Yiru Chen</li> <li>Zachary Elliott</li> <li>Pinqian Jin</li> <li>Alex Saul</li> <li>Sebastian Tan</li> <li>Jim Zhu</li> </ul>"},{"location":"#advisors","title":"Advisors","text":"<ul> <li>Lee Stott - Microsoft Principal Cloud Advocate</li> <li>Nitya Narasimhan - Microsoft Senior Cloud Advocate</li> <li>Sonali Parbhoo - Lecturer, Imperial College London</li> </ul>"},{"location":"#projects","title":"Projects","text":"Repository name Repo Size Issues Closed Issues Open Commit Activity <code>Contoso Chat</code> <code>Contoso Web</code>"},{"location":"01%20Introduction/1%20Project%20Overview/","title":"1| Project Overview","text":""},{"location":"01%20Introduction/1%20Project%20Overview/#motivation","title":"Motivation","text":"<p>Nowadays, businesses starts to make use of Generative AI for chatbot applications to enhance users' online shopping experience. However, many face three huge challenges:</p> <ul> <li>Costs: Deploying proprietary AI models, such as those from OpenAI on Azure, can be prohibitively expensive. Our tests indicate that maintaining these models can cost around $10 per day, which would quickly add up when the business scale increases. </li> <li>Integration: Different models are required for embedding, chat completion, and evaluation. Choosing the right model combination and ensuring they work seamlessly together can be complex and time-consuming.</li> <li>Accessibility: There's a need to cater to a diverse user base, ensuring that AI-driven solutions are accessible and usable for everyone, including those who have difficulty reading or writing.</li> </ul>"},{"location":"01%20Introduction/1%20Project%20Overview/#objective","title":"Objective","text":"<p>This project aims to explore the viability of using open-source models from Hugging Face to reconstruct the Contoso Chat retail copilot application originally developed by Microsoft. By integrating these models into the Contoso Chat application, we aim to address the challenges stated in the Motivation section and make AI chatbot more accessible to all online retailers. </p>"},{"location":"01%20Introduction/1%20Project%20Overview/#key-accomplishments","title":"Key Accomplishments","text":"<ul> <li>Hugging Face Model Integration: Builds a framework for integrating the Hugging Face platform\u2019s vast library of AI models with Contoso Chat for text embedding, chat completion and evaluation tasks.</li> <li>Enhanced UI: Introduces a new audio input/output feature to improve user accessibility.</li> <li>Model Recommendation: Evaluates and compares the performances of popular Large Language Models on the chat completion task. Makes automatic model recommendation based on evaluation scores.</li> </ul> <p>Our testing shows promising results in terms of AI accuracy and user satisfaction. The documentation provides detailed insights into the development process and our learnings.</p>"},{"location":"01%20Introduction/1%20Project%20Overview/#future-work","title":"Future Work","text":"<p>We plan to enhance the project with several key developments:</p> <ul> <li>Add an Extra LLM Layer to Analyze Evaluation Results: Implement an additional layer to process and interpret evaluation data, making the evaluation results more comprehensible for everyone.</li> <li>Create a System to Recommend Suitable Model Configuration: Develop a recommendation system to suggest optimal model configurations based on specific use cases and requirements.</li> <li>Create a More Comprehensive Evaluation Method: Design and implement more detailed and nuanced evaluation matrices to better assess model performance across various metrics and dimensions.</li> <li>Explore Different Methods of Deploying the Whisper Model to Reduce Latency: Investigate and implement various deployment strategies for the Whisper model to minimize response times and improve user experience.</li> <li>Implement Multiple Language Support: Extend the application to support multiple languages by using embeddings tailored to different linguistic contexts, making the tool accessible to a broader audience.</li> </ul>"},{"location":"01%20Introduction/2%20Software%20Architecture/","title":"2| Software Architecture","text":"<p>Our software architecture for the Contoso Project integrates various technologies to deliver a robust and scalable chatbot application, including next.js, Python, Hugging Face, AI Studie, Prompt Flow, Azd CLI, Tailwind, AI search, and Cosmo DB. Below is an overview of the key components and their interactions within our system.</p>"},{"location":"01%20Introduction/2%20Software%20Architecture/#system-overview","title":"System Overview","text":""},{"location":"01%20Introduction/2%20Software%20Architecture/#key-components","title":"Key Components","text":"<ol> <li> <p>Chat Interface: Accepts prompts from the retail website user in either text or audio format.</p> </li> <li> <p>Speech to Text Model: If the prompt is in audio format, it is sent to a Whisper model on Hugging Face for transcription.</p> </li> <li> <p>Chat Function: Acts as the \"brain\" of Contoso Chat, serving as the interface between Hugging Face models and Azure services.</p> </li> <li> <p>Embedding Model: Converts incoming queries into multidimensional vectors to aid in semantic search.</p> </li> <li> <p>Azure AI Search: Uses vectors produced by the embedding model to search for relevant and semantically similar documents from the database.</p> </li> <li> <p>Cosmos DB: The database containing catalogues, product information, and customer data, which is queried and used to generate responses.</p> </li> <li> <p>Chat Completion Model: Combines vectorized prompts from the embedding model with knowledge from Azure AI Search to generate a chat response. This response is sent back to the user via API.</p> </li> <li> <p>Text to Speech Model: Converts the chat response produced into an audio output using models like ElevenLabs.</p> </li> <li> <p>Evaluation Model: Benchmarks the performance of the chat completion model by systematically testing it through detailed metrics.</p> </li> </ol>"},{"location":"01%20Introduction/2%20Software%20Architecture/#interaction-flow","title":"Interaction Flow","text":"<ol> <li>User Prompt: The user provides a prompt via the chat interface.</li> <li>Transcription (if needed): Audio prompts are transcribed into text using the Whisper model.</li> <li>Query Handling: The text prompt is processed by the chat function and sent to the embedding model.</li> <li>Semantic Search: The embedding model converts the query into vectors, which are then used by Azure AI Search to find relevant documents in Cosmos DB.</li> <li>Response Generation: The chat completion model combines information from the embedding model and Azure AI Search to generate a response.</li> <li>Output Delivery: The response is sent back to the user. If the user prefers audio, it is converted using a text to speech model.</li> </ol> <p>This architecture ensures a seamless and efficient flow of information, providing users with accurate and contextually relevant responses.</p>"},{"location":"02%20Contoso%20Chat/1%20Evaluation/","title":"1| Evaluation","text":"<p>A thorough evaluation process is conducted for ChatGPT models as well as a number of free Hugging Face models to assess their performance in generating text responses. The detailed methodology and results of this evaluation are presented on this page.</p>"},{"location":"02%20Contoso%20Chat/1%20Evaluation/#methodology","title":"Methodology","text":"<p>Each of the models is evaluated based on four metrics: Coherence, Groundedness, Fluency, and Relevance. Our evaluation process involves the use of Python scripts that calculate a weighted sum score for each model and automatically select the best-fitting model. Our evaluation system recommends the best model and model parameters based on a weighted sum score of the four evaluation metrics.</p>"},{"location":"02%20Contoso%20Chat/1%20Evaluation/#auto-evaluation-process","title":"Auto-Evaluation Process","text":"<ol> <li>Check if Model Exists in Connection List</li> <li>Update Vector Search Based on Embedding</li> <li>Calculate the 4 Evaluation Metrics</li> <li>Save Results and Update Log Files</li> <li>Create Summary Table</li> <li>Populate HTML Page and Save to Local Directory</li> </ol> <p>The system returns a dynamic HTML page that the developer can interact with to view results.</p>"},{"location":"02%20Contoso%20Chat/1%20Evaluation/#results","title":"Results","text":"<ul> <li>Paid vs. Free Models: Free models do not perform as well as the paid ChatGPT 3.5, which scores high in each of the four metrics. However, each free model has its own strength (e.g., groundedness for meta_llama3 and fluency for phi_3).</li> <li>Flexibility: Companies can easily switch between different free models based on the features they prioritize.</li> </ul>"},{"location":"02%20Contoso%20Chat/1%20Evaluation/#model-performance-comparison","title":"Model Performance Comparison","text":"<p>Below are the spider graphs representing the evaluation metrics for the top models:</p>"},{"location":"02%20Contoso%20Chat/1%20Evaluation/#graph-1-top-4-models-evaluation-results","title":"Graph 1: Top 4 Models Evaluation Results","text":""},{"location":"02%20Contoso%20Chat/1%20Evaluation/#graph-2-model-meta_llama3_instruct_70b-with-different-model-configurations","title":"Graph 2: Model meta_llama3_instruct_70B with different model configurations","text":""},{"location":"02%20Contoso%20Chat/1%20Evaluation/#graph-3-model-phi_3_mini_4k_instruct-with-different-model-configurations","title":"Graph 3: Model Phi_3_mini_4k_instruct with different model configurations","text":""},{"location":"03%20Contoso%20Web/1%20Overview/","title":"1| Contoso Web Overview","text":"<p>Contoso Web is a showcase of the Contoso Chat integrated into a fake retail website, Contoso Outdoors. This integration demonstrates how advanced AI-driven customer support can enhance the user experience on e-commerce platforms.</p>"},{"location":"03%20Contoso%20Web/1%20Overview/#contoso-outdoors-website","title":"Contoso Outdoors (Website)","text":"<p>The Contoso Outdoors site is designed as a comprehensive and user-friendly web application featuring a product catalog neatly organized into categories such as Tents and Backpacks. - Landing Page: The website landing page displays the Contoso Outdoors product catalog, organized into intuitive categories for easy navigation. </p> <ul> <li>Product Details Page: When a customer clicks on a product, they are taken to a detailed product page. This page provides extensive information to assist customers in making informed purchase decisions. </li> </ul>"},{"location":"03%20Contoso%20Web/1%20Overview/#contoso-chat-integration","title":"Contoso Chat Integration","text":"<p>The Contoso Chat (LLM App) is seamlessly integrated into the Contoso Outdoors site via a chat icon located at the bottom right of the screen. This integration allows customers to interact with the chat AI for support and information directly on the website. </p> <p>For more details, please visit Contoso Chat Scenario.</p>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/","title":"2| Audio Input/Output Function","text":"<p>As part of enhancing user interaction on the Contoso Outdoors site, we have integrated audio input and output capabilities into the Contoso Chat. This feature allows users to interact with the chatbot using their voice, making the interaction more natural and accessible.</p>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#workflow","title":"Workflow","text":""},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#audio-input","title":"Audio Input","text":"<ol> <li>Start: User initiates interaction by pressing the microphone button.</li> <li>Record Audio Prompt: If the microphone button is pressed, the system records the audio prompt.</li> <li>Speech-to-Text Processing: The audio prompt is sent to the Whisper-large-v3 model for transcription.</li> <li>Text Prompt: The transcribed text is returned to the chat interface and sent to the backend for inference.</li> </ol>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#text-input","title":"Text Input","text":"<ol> <li>Text Prompt Entry: If the microphone button is not pressed, the user types in their text prompt.</li> <li>Backend Processing: The text prompt is sent to the backend for inference.</li> <li>Chat Response: The response is generated by the backend and returned to the user interface.</li> </ol>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#audio-output","title":"Audio Output","text":"<ol> <li>Text Response: The text response is converted to speech using the 11-Labs Turbo V2 model.</li> <li>Playback: The audio file is returned to the chat interface and read out to the user.</li> </ol>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#models-used","title":"Models Used","text":""},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#speech-to-text-model","title":"Speech-to-Text Model","text":"<ul> <li>Model: Whisper-large-v3</li> <li>Latency: 11583ms</li> <li>Features:</li> <li>Free use via Hugging Face Inference API</li> <li>Multi-language support</li> </ul>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#text-to-speech-model","title":"Text-to-Speech Model","text":"<ul> <li>Model: 11-Labs Turbo V2</li> <li>Latency: 457ms</li> <li>Features:</li> <li>Free use (up to 10,000 tokens)</li> <li>Optimized LLM for real-time applications</li> </ul>"},{"location":"03%20Contoso%20Web/2%20Audio%20Input%20and%20Output/#benefits","title":"Benefits","text":"<ul> <li>Accessibility: Enhances accessibility by allowing users to interact using voice commands.</li> <li>Convenience: Provides a more natural and convenient way for users to interact with the chatbot.</li> <li>Efficiency: Reduces the time taken for user input and response generation, especially for users who prefer speaking over typing.</li> </ul>"}]}